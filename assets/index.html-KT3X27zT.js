const e=JSON.parse('{"key":"v-48487511","path":"/dl/neural_de/node/","title":"神经常微分方程","lang":"zh-CN","frontmatter":{"title":"神经常微分方程","headerDepth":2,"description":"神经常微分方程（简称：NeuralODE）是一种通过使用神经网络参数化向量场来结合常微分方程和神经网络的一种全新的深度学习模型。在2018年首次被提出和使用，它将传统的有限层神经网络架构转变为参数共享的无限层神经网络架构，弥合了深度学习和动态系统的差距。NODE从网络架构，训练方法，超参数选择，表示能力等均和传统的神经网络例如CNN,MLP，RNN等有...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/vuepresss/dl/neural_de/node/"}],["meta",{"property":"og:site_name","content":"丁善伟"}],["meta",{"property":"og:title","content":"神经常微分方程"}],["meta",{"property":"og:description","content":"神经常微分方程（简称：NeuralODE）是一种通过使用神经网络参数化向量场来结合常微分方程和神经网络的一种全新的深度学习模型。在2018年首次被提出和使用，它将传统的有限层神经网络架构转变为参数共享的无限层神经网络架构，弥合了深度学习和动态系统的差距。NODE从网络架构，训练方法，超参数选择，表示能力等均和传统的神经网络例如CNN,MLP，RNN等有..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2023-11-30T13:17:52.000Z"}],["meta",{"property":"article:author","content":"Shanwei"}],["meta",{"property":"article:modified_time","content":"2023-11-30T13:17:52.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"神经常微分方程\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2023-11-30T13:17:52.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"Shanwei\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[],"git":{"createdTime":1701224999000,"updatedTime":1701350272000,"contributors":[{"name":"shanwei","email":"2369313525@qq.com","commits":3}]},"readingTime":{"minutes":1.1,"words":329},"filePathRelative":"dl/neural_de/node/README.md","localizedDate":"2023年11月29日","autoDesc":true,"excerpt":""}');export{e as data};
